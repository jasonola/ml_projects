{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the work is done, I make my comment. It was a very interesting project to make, I learnt a lot throughout the phases of the project and was very well challenged. I experimented new libraries like yellowbrick for some nice visualizations and used new techniques like dimensionality reduction with UMAP, multiple inputs neural networks, sklearn wrapping for keras models (with lot's of trial and error with the 2 lasts). I had some trouble for a lot of things like removing the white frame around the image, I remember spending a whole afternoon figuring out 2 lines of code. There was also practical things like how to save my variables between my notebooks, I ended up just using the magic command %store that has proven very usefull, I also had problems with where to start saving stuff, I had to go back multiple times here and there to save some stuff, to erase other stuff, I don't think I have planned that thoroughly but in the end everything is at it's place. Oh and the grid search on keras models with the transformation of the model into a sklearn model-like is quite easy after all, but it took time to figure out, I ended up giving this up with the multi-input model, I had ideas like transforming the functional model to sequencial and then put it in a grid search, it worked all the way until I had to test it and never figured how to do it. I've seen on forums that multi inputs does not go well in sklearn wrapping so I did the good old model fit predict stuff to come up with my confusion matrix and report.\n",
    "\n",
    "Even if I didn't do much with the sound wave files, I learnt a lot, the vocabulary, the math, the feature extraction and all with the librosa package thanks to an excellent youtube playlist : https://www.youtube.com/playlist?list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0 that I encourage you to check out if you want to get in the audio realm. \n",
    "\n",
    "Would a machine have a hard time classifying music genre as we do ? That was my machine learning question for this project. I had interesting results, I found that in most models classical music and metal were classified well most of the time. Which to me is not so surprising as these are very recognisable sounds to me, whereas rock had worse results. Rock to me too is understandable, it's like a bridge between some of these genre, it was often mixed up with country, blues and metal. I could see this in the biplots, where rock was in the center and mixed a bit everywhere. I've seen similar mixups between hip hop and reggae too. To answer my question, I think models would have the same problems of classifying music as we do, I also think that the fact that a lot of genres get mixed up due to different music influence, cultural influence and other stuff probably, makes that complicated for us even to classify genres. Maybe even some songs that are labeled as rock in the begining, I could think they are blues. Hence I'm thinking that maybe, if we had multiple labels for each song, my models would probably do much better.\n",
    "\n",
    "I am overall happy with my results, I think that we as human can probably do better but the models are not that far from reality or at least not far from the music listener who is not punctilious enough to know the difference between rock and blues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
